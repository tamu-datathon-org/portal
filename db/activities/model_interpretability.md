---
name: "Model Interpretability"
id: model_interpretability
startTime: October 18, 2020 12:00:00-500
endTime: October 18, 2020 13:15:00-500
duration: 75
mediaType: meeting_url
eventId: 5f1bc49319f52100035dda03
mediaLink: https://tamu.zoom.us/j/94695038191
thumbnail: https://firebasestorage.googleapis.com/v0/b/td2020-fb428.appspot.com/o/Frame%206.png?alt=media&token=6197430c-42e9-4db0-b342-95490a63426f
presenter: Alan Feder
presenterAbout: Alan Feder is a Principal Data Scientist currently working for Invesco Mutual Funds. Prior to Invesco, Alan worked for 8 years gaining actuarial and data science experience in finance. Alan has a Bachelors Degree in Mathematics & Economics from Columbia University, and a Masters in Statistics from Columbia as well.
presenterSocials:
  - type: Alan's LinkedIn
    link: https://www.linkedin.com/in/alanfeder/
priority: 7
relatedActivities: null
tags: explainability, partial dependence, LIME, conditional expectation, SHAP
---

How do we interpret the results from our models? As we develop newer and better machine learning models, they grow more and more difficult to draw results from. In this workshop, we will go over techniques for making contemporary models easier to interpret.

---

- tags: explainability, partial dependence, LIME, conditional expectation, SHAP

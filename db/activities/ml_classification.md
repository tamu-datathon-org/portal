---
name: "ML Introduction Part 2/2: Applied"
startTime: October 17, 2020 21:30:00-500
endTime: October 17, 2020 22:45:00-500
duration: 75
eventId: 5f8a0ac733c190000312a9d0
mediaType: embed_url
mediaLink: https://www.youtube.com/embed/C5OAzSx-Ux0
thumbnail: https://mcusercontent.com/36d73585139760aa245837bb2/images/0dd3d528-a1b1-481c-8ccf-01e7913ae268.jpeg
presenter: Allyson King
presenterAbout: Allyson is the VP of TAMU Datathon, a BS Statistics and (almost) Computer Science, and has worked at AT&T and TTI.
presenterSocials:
  - type: Allyson's Medium
    link: https://medium.com/@allysonmking
  - type: Allyson's LinkedIn
    link: https://www.linkedin.com/in/allysonmking
priority: 7
relatedActivities:
  - data_science_202
  - data_science_303
  - data_science_404
tags: applied, random forests, decision trees, xgboost, boosting, hyperparameter tuning, sklearn, evaluation, feature selection, test train split, machine learning
---

In this workshop we will take you though one of the most powerful ML algorithms: Decision Trees. We will follow that up with a form of bagging called Random Forests and then a form of boosting called XGBoost.
Finally, weâ€™ll teach how to avoid overfitting through cross validation, hyperparameter tuning and feature selection. All of this will be done in Python with sklearn. Looking forward to seeing you there!

---

- tags: applied, random forests, decision trees, xgboost, boosting, hyperparameter tuning, sklearn, evaluation, feature selection, test train split, machine learning
